{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e64d020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c8cf15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CitationSpan:\n",
    "    chunk_id: str\n",
    "    source: Optional[str]\n",
    "    page: Optional[int]\n",
    "    start_char: int\n",
    "    end_char: int\n",
    "    section: Optional[str]\n",
    "    clause: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Section Detector - Hierarchical section detection\n",
    "\n",
    "SECTION_PATTERNS = [\n",
    "    r\"^SECTION\\s+\\d+\",\n",
    "    r\"^ARTICLE\\s+\\d+\",\n",
    "    r\"^\\d+\\.\",\n",
    "    r\"^[A-Z][A-Z\\s]{4,}$\"\n",
    "]\n",
    "\n",
    "section_regex = re.compile(\"|\".join(SECTION_PATTERNS))\n",
    "\n",
    "def detect_sections(text: str):\n",
    "    current = \"INTRO\"\n",
    "    mapping = []\n",
    "\n",
    "    for line in text.split(\"\\n\"):\n",
    "        if section_regex.match(line.strip()):\n",
    "            current = line.strip()\n",
    "\n",
    "        mapping.append((line, current))\n",
    "\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc348b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clause Detector\n",
    "\n",
    "CLAUSE_RE = re.compile(\n",
    "    r\"(Section|Clause|Article|Topic)\\s+\\d+(\\.\\d+)*(\\([a-z]\\))*\",\n",
    "    re.I\n",
    ")\n",
    "\n",
    "def extract_clauses(text: str):\n",
    "    matches = CLAUSE_RE.findall(text)\n",
    "    return [\"\".join(m) for m in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ee14cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chunk Enricher - Add inheritance + section + clause_metadata\n",
    "\n",
    "def enrich_chunk_metadata(parent_meta, extra_meta, chunk_text):\n",
    "    meta = deepcopy(parent_meta or {})\n",
    "    meta.update(extra_meta)\n",
    "\n",
    "    clauses = extract_clauses(chunk_text)\n",
    "    if clauses:\n",
    "        meta[\"clauses\"] = clauses\n",
    "\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "815a11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Citation Merge\n",
    "\n",
    "def merge_adjacent_spans(spans, gap=80):\n",
    "    spans = sorted(spans, key=lambda s: (s.page, s.start_char))\n",
    "    merged = []\n",
    "\n",
    "    for s in spans:\n",
    "        if not merged:\n",
    "            merged.append(s)\n",
    "            continue\n",
    "\n",
    "        last = merged[-1]\n",
    "\n",
    "        same_page = last.page == s.page\n",
    "        close = s.start_char <= last.end_char + gap\n",
    "\n",
    "        if same_page and close:\n",
    "            last.end_char = max(last.end_char, s.end_char)\n",
    "        else:\n",
    "            merged.append(s)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba124bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Highlight\n",
    "\n",
    "def highlight_text(text, start, end):\n",
    "    return text[:start] + \"<mark>\" + text[start:end] + \"</mark>\" + text[end:]\n",
    "\n",
    "\n",
    "def extract_span(text, start, end):\n",
    "    return text[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3daf147",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Formatter - Frontend-ready answer formatter\n",
    "\n",
    "def format_answer(answer_text, citation_spans):\n",
    "    citations = []\n",
    "\n",
    "    for s in citation_spans:\n",
    "        citations.append({\n",
    "            \"chunk_id\": s.chunk_id,\n",
    "            \"source\": s.source,\n",
    "            \"page\": s.page,\n",
    "            \"section\": s.section,\n",
    "            \"clause\": s.clause,\n",
    "            \"start_char\": s.start_char,\n",
    "            \"end_char\": s.end_char\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer_text,\n",
    "        \"citations\": citations\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2936ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RAG Citation Pipeline - This is the glue layer you call after retrieval\n",
    "\n",
    "def build_citation_spans(retrieved_docs):\n",
    "    spans = []\n",
    "\n",
    "    for d in retrieved_docs:\n",
    "        m = d.metadata\n",
    "\n",
    "        spans.append(CitationSpan(\n",
    "            chunk_id=m[\"chunk_id\"],\n",
    "            source=m.get(\"source\"),\n",
    "            page=m.get(\"page\"),\n",
    "            start_char=m[\"start_char\"],\n",
    "            end_char=m[\"end_char\"],\n",
    "            section=m.get(\"section_title\"),\n",
    "            clause=(m.get(\"clauses\") or [None])[0]\n",
    "        ))\n",
    "\n",
    "    return spans\n",
    "\n",
    "\n",
    "def rag_citation_pipeline(answer_text, retrieved_docs):\n",
    "    spans = build_citation_spans(retrieved_docs)\n",
    "\n",
    "    merged = merge_adjacent_spans(spans)\n",
    "\n",
    "    return format_answer(answer_text, merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Integration Example\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate \n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"What is good name for a company that makes {product}\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "result = chain.run(product=\"colorful socks\")\n",
    "print(result)\n",
    "\n",
    "retrieved = retriever.invoke(query)\n",
    "\n",
    "result = rag_citation_pipeline(\n",
    "    answer_text=llm_answer,\n",
    "    retrieved_docs=retrieved\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6040c6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
