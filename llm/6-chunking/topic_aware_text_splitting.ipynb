{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740f6028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-experimental\n",
      "  Downloading langchain_experimental-0.4.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-experimental) (1.2.11)\n",
      "Requirement already satisfied: langchain-community<1.0.0,>=0.4.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-experimental) (0.4.1)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.0.46)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (9.1.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.7.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (26.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-experimental) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.0.0)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.25.0)\n",
      "Requirement already satisfied: anyio in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.5->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.5->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.3.1)\n",
      "Downloading langchain_experimental-0.4.1-py3-none-any.whl (210 kB)\n",
      "Installing collected packages: langchain-experimental\n",
      "Successfully installed langchain-experimental-0.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91551681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a93c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (1.2.13)\n",
      "Requirement already satisfied: langchain-community in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (0.4.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-core) (0.7.1)\n",
      "Requirement already satisfied: packaging>=23.2.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-core) (26.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-core) (2.12.3)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-core) (9.1.4)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-core) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community) (2.0.46)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-community) (2.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jeremy/Documents/Work/Learning/fastapi/venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade langchain-core langchain-community\n",
    "import os\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import networkx as nx\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac0f8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: 1865 characters, Metadata: {'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Copy of 251102 PromptBI Analysts Training Agreement Draft v.2', 'source': '/home/jeremy/Documents/Work/Learning/fastapi/llm/4-document_loader/sample_data/document.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}\n",
      "Page 2: 3041 characters, Metadata: {'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Copy of 251102 PromptBI Analysts Training Agreement Draft v.2', 'source': '/home/jeremy/Documents/Work/Learning/fastapi/llm/4-document_loader/sample_data/document.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}\n",
      "Page 3: 1750 characters, Metadata: {'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Copy of 251102 PromptBI Analysts Training Agreement Draft v.2', 'source': '/home/jeremy/Documents/Work/Learning/fastapi/llm/4-document_loader/sample_data/document.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}\n",
      "Page 4: 106 characters, Metadata: {'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Copy of 251102 PromptBI Analysts Training Agreement Draft v.2', 'source': '/home/jeremy/Documents/Work/Learning/fastapi/llm/4-document_loader/sample_data/document.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}\n",
      "[Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Copy of 251102 PromptBI Analysts Training Agreement Draft v.2', 'source': '/home/jeremy/Documents/Work/Learning/fastapi/llm/4-document_loader/sample_data/document.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='PromptBI  Analyst  Agreement  \\nThis  Agreement  is  made  between:  \\n●  PromptBI  Ltd  (“PromptBI”),  and  \\n ●  [Jeremiah  Katumo  Kurwa]  (“Analyst”)  \\n \\nEffective  Date:   \\n \\n1.  Purpose  \\n1.1  PromptBI  operates  a  training  and  placement  programme  (the  “Programme”)  designed  to  \\ndevelop\\n \\nprofessional\\n \\nskills\\n \\nin\\n \\nprompt\\n \\nengineering,\\n \\nAI-human\\n \\ncollaboration,\\n \\napplied\\n \\nanalytics,\\n \\nstakeholder\\n \\nmanagement,\\n \\nand\\n \\nrelated\\n \\ncompetencies.\\n \\n1.2  The  Analyst  wishes  to  participate  in  the  Programme  and  to  be  placed  with  a  Host  \\nBusiness\\n \\nfor\\n \\na\\n \\nﬁxed\\n \\ntwelve-month\\n \\nperiod,\\n \\nsubject\\n \\nto\\n \\nthe\\n \\nterms\\n \\nof\\n \\nthis\\n \\nAgreement.\\n \\n2.  Status  \\n2.1  The  Analyst  acknowledges  and  agrees  that  nothing  in  this  Agreement  creates  an  \\nemployment\\n \\nrelationship,\\n \\npartnership,\\n \\nagency,\\n \\nor\\n \\njoint\\n \\nventure\\n \\nbetween\\n \\nthe\\n \\nAnalyst\\n \\nand\\n \\nPromptBI.\\n \\n2.2  PromptBI’s  sole  obligations  under  this  Agreement  are  to  provide  training,  mentorship,  \\nand\\n \\nfacilitation\\n \\nof\\n \\nplacement\\n \\nopportunities.\\n \\nPromptBI\\n \\ndoes\\n \\nnot\\n \\nsupervise\\n \\nthe\\n \\nAnalyst’s\\n \\nwork\\n \\nat\\n \\nthe\\n \\nHost\\n \\nBusiness\\n \\nand\\n \\nis\\n \\nnot\\n \\nresponsible\\n \\nfor\\n \\nthe\\n \\nAnalyst’s\\n \\nperformance.\\n \\n2.3  The  Analyst  remains  responsible  for  all  obligations  under  any  direct  contract  with  the  \\nHost\\n \\nBusiness,\\n \\nincluding\\n \\ncompliance\\n \\nwith\\n \\nworkplace\\n \\npolicies,\\n \\ninsurance,\\n \\nand\\n \\nemployment\\n \\nlaws.\\n \\n3.  Training  and  Placement  Accounts  \\n3.1  PromptBI  shall  provide  the  Analyst  with  access  to  training,  mentorship,  and  the  \\nPromptBI\\n \\nplatform\\n \\nduring\\n \\nthe\\n \\nProgramme.\\n \\n3.2  The  Analyst  shall  maintain  a  personal  training  account  within  the  PromptBI  platform.  \\nThis\\n \\naccount\\n \\nis\\n \\nthe\\n \\nproperty\\n \\nof\\n \\nthe\\n \\nAnalyst\\n \\nand\\n \\nremains\\n \\nunder\\n \\ntheir\\n \\ncontrol\\n \\nthroughout\\n \\nthe\\n \\nProgramme.'), Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Copy of 251102 PromptBI Analysts Training Agreement Draft v.2', 'source': '/home/jeremy/Documents/Work/Learning/fastapi/llm/4-document_loader/sample_data/document.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='3.3  The  business  account,  linked  to  the  Analyst’s  placement,  remains  the  property  of  the  \\nHost\\n \\nBusiness\\n.\\n \\nThe\\n \\nAnalyst’s\\n \\naccess\\n \\nto\\n \\nthe\\n \\nbusiness\\n \\naccount\\n \\nis\\n \\nconditional\\n \\non\\n \\nthe\\n \\nplacement\\n \\nand\\n \\nmay\\n \\nbe\\n \\nsuspended\\n \\nor\\n \\nterminated\\n \\nin\\n \\naccordance\\n \\nwith\\n \\nthe\\n \\narrangement\\n \\nbetween\\n \\nPromptBI\\n \\nand\\n \\nthe\\n \\nHost\\n \\nBusiness.\\n \\n3.4  The  Analyst  shall  participate  fully  in  all  required  training  and  mentorship  sessions  to  \\nensure\\n \\nreadiness\\n \\nfor\\n \\nplacement.\\n \\n4.  Training,  Fee,  and  Veriﬁcation  \\n4.1  PromptBI  shall  provide  the  Analyst  with  access  to  ongoing  training,  mentorship,  and  a  \\npersonal\\n \\nPromptBI\\n \\naccount\\n \\nfor\\n \\nthe\\n \\nduration\\n \\nof\\n \\nthe\\n \\nProgramme.\\n \\n4.2  In  consideration  of  the  training,  mentorship,  and  platform  access  provided  under  this  \\nAgreement,\\n \\nthe\\n \\nAnalyst\\n \\nshall\\n \\npay\\n \\nPromptBI\\n \\na\\n \\nservice\\n \\nand\\n \\nmanagement\\n \\nfee\\n \\nequal\\n \\nto\\n \\nﬁfteen\\n \\npercent\\n \\n(15%)\\n \\nof\\n \\nthe\\n \\ngross\\n \\nsalary\\n \\nor\\n \\nstipend\\n \\nactually\\n \\nreceived\\n \\nfrom\\n \\nthe\\n \\nHost\\n \\nBusiness\\n.\\n \\n4.3  The  Analyst  shall  provide  PromptBI  with  documentation  evidencing  the  gross  salary  or  \\nstipend\\n \\nreceived\\n \\nfrom\\n \\nthe\\n \\nHost\\n \\nBusiness.\\n \\nSuch\\n \\ndocumentation\\n \\nshall\\n \\nbe\\n \\nprovided\\n \\nprior\\n \\nto\\n \\nthe\\n \\nﬁrst\\n \\npayment\\n \\nand\\n \\nupon\\n \\nany\\n \\nchange\\n \\nto\\n \\nthe\\n \\namount\\n \\nreceived.\\n \\n4.4  Payment  of  the  service  and  management  fee  shall  be  made  monthly ,  either  via  invoice  \\nissued\\n \\nby\\n \\nPromptBI\\n \\nor\\n \\nthrough\\n \\na\\n \\npayment\\n \\nlink\\n \\nprovided\\n \\nby\\n \\nPromptBI,\\n \\nor\\n \\nthrough\\n \\nany\\n \\nother\\n \\nmethod\\n \\nas\\n \\nagreed\\n \\nbetween\\n \\nPromptBI\\n \\nand\\n \\nthe\\n \\nAnalyst.\\n \\nNo\\n \\nfee\\n \\nshall\\n \\nbe\\n \\npayable\\n \\nfor\\n \\nany\\n \\nmonth\\n \\nin\\n \\nwhich\\n \\nthe\\n \\nAnalyst\\n \\ndoes\\n \\nnot\\n \\nreceive\\n \\nsalary\\n \\nor\\n \\nstipend\\n \\nfrom\\n \\nthe\\n \\nHost\\n \\nBusiness.\\n \\n4.5  The  Analyst  authorises  PromptBI  to  use  the  provided  documentation  solely  for  the  \\npurpose\\n \\nof\\n \\ncalculating\\n \\nthe\\n \\nservice\\n \\nand\\n \\nmanagement\\n \\nfee.\\n \\nPromptBI\\n \\nshall\\n \\ntreat\\n \\nsuch\\n \\ninformation\\n \\nas\\n \\nconﬁdential\\n \\nand\\n \\nshall\\n \\nnot\\n \\ndisclose\\n \\nit\\n \\nexcept\\n \\nas\\n \\nrequired\\n \\nto\\n \\nenforce\\n \\nthis\\n \\nAgreement\\n \\nor\\n \\nby\\n \\nlaw.\\n \\n5.  Intellectual  Property  and  Conﬁdentiality  \\n5.1  The  Analyst  shall  comply  with  all  conﬁdentiality  obligations  imposed  by  the  Host  \\nBusiness\\n \\nand,\\n \\nat\\n \\na\\n \\nminimum,\\n \\ntreat\\n \\nall\\n \\nbusiness-related\\n \\ninformation\\n \\nas\\n \\nconﬁdential.\\n \\n5.2  Intellectual  property  created  by  the  Analyst  using  the  Host  Business’s  data  or  in  the  \\ncourse\\n \\nof\\n \\ntheir\\n \\nplacement\\n \\nshall\\n \\nbelong\\n \\nexclusively\\n \\nto\\n \\nthe\\n \\nHost\\n \\nBusiness.\\n \\n5.3  Intellectual  property  created  by  the  Analyst  independently  or  during  training  provided  \\nby\\n \\nPromptBI\\n \\nshall\\n \\nremain\\n \\nthe\\n \\nproperty\\n \\nof\\n \\nthe\\n \\nAnalyst.\\n \\n5.4  The  Analyst  shall  not  disclose  or  misuse  any  PromptBI  materials  or  platform  features  \\nbeyond\\n \\nthe\\n \\npurposes\\n \\nof\\n \\nthe\\n \\nProgramme.\\n \\n6.  Termination  \\n6.1  This  Agreement  shall  terminate  upon  the  earlier  of:'), Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Copy of 251102 PromptBI Analysts Training Agreement Draft v.2', 'source': '/home/jeremy/Documents/Work/Learning/fastapi/llm/4-document_loader/sample_data/document.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='(a)  completion  of  the  twelve-month  placement;  or  \\n(b)  removal  of  the  Analyst  from  the  Programme  by  PromptBI  due  to  \\nunderperformance\\n \\nor\\n \\nother\\n \\nreasons\\n \\ndetermined\\n \\nin\\n \\naccordance\\n \\nwith\\n \\nthe\\n \\nProgramme\\n \\nrules.\\n \\n6.2  In  the  event  the  Analyst’s  placement  with  a  Host  Business  ends  for  reasons  other  than  \\nunderperformance,\\n \\nPromptBI\\n \\nshall\\n \\nuse\\n \\nreasonable\\n \\nefforts\\n \\nto\\n \\narrange\\n \\nan\\n \\nalternative\\n \\nplacement\\n \\nfor\\n \\nthe\\n \\nremainder\\n \\nof\\n \\nthe\\n \\ntwelve-month\\n \\nperiod.\\n \\n6.3  Termination  of  this  Agreement  shall  also  terminate  access  to  the  business  account.  No  \\nrefund\\n \\nof\\n \\nfees\\n \\npaid\\n \\nshall\\n \\nbe\\n \\nmade.\\n \\n7.  Limitation  of  Liability  \\n7.1  PromptBI  shall  not  be  liable  for  any  loss,  damage,  or  expense  arising  from  the  Analyst’s  \\nwork,\\n \\nconduct,\\n \\nor\\n \\nperformance\\n \\nat\\n \\nthe\\n \\nHost\\n \\nBusiness.\\n \\n7.2  The  Analyst  acknowledges  that  participation  in  the  Programme  is  at  their  own  risk,  and  \\nthat\\n \\nPromptBI\\n \\nprovides\\n \\nno\\n \\nguarantees\\n \\nregarding\\n \\nplacement\\n \\noutcomes,\\n \\nstipend\\n \\namounts,\\n \\nor\\n \\ncareer\\n \\nprogression.\\n \\n8.  General  Provisions  \\n8.1  This  Agreement  constitutes  the  entire  agreement  between  the  Parties  with  respect  to  \\nthe\\n \\nsubject\\n \\nmatter\\n \\nherein\\n \\nand\\n \\nsupersedes\\n \\nall\\n \\nprior\\n \\ncommunications,\\n \\nunderstandings,\\n \\nand\\n \\nagreements.\\n \\n8.2  Any  amendments  or  modiﬁcations  to  this  Agreement  shall  be  in  writing  and  signed  by  \\nboth\\n \\nParties.\\n \\n8.3  This  Agreement  shall  be  governed  by  and  construed  in  accordance  with  the  laws  of  \\nKenya.\\n \\n \\nSigned:  \\n        \\n_______________________________________  _______________________________________  \\nName:  Name:  Jeremiah  Katumo  Kurwa'), Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Copy of 251102 PromptBI Analysts Training Agreement Draft v.2', 'source': '/home/jeremy/Documents/Work/Learning/fastapi/llm/4-document_loader/sample_data/document.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='For  and  on  behalf  of  PromptBI  Analyst  \\nDate:  __________________________________  Date:  12/11/2025')]\n"
     ]
    }
   ],
   "source": [
    "def load_pdf(pdf_path: str) -> List[Document]:\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        for i, doc in enumerate(documents):\n",
    "            print(f\"Page {i+1}: {len(doc.page_content)} characters, Metadata: {doc.metadata}\")\n",
    "            \n",
    "        return documents\n",
    "    except Exception as e: \n",
    "        print(f\"Error loading PDF: {e}\")\n",
    "        return []\n",
    "    \n",
    "pdf_path = '/home/jeremy/Documents/Work/Learning/fastapi/llm/4-document_loader/sample_data/document.pdf'\n",
    "documents = load_pdf(pdf_path)\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c5dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def topic_aware_text_splitting(\n",
    "    documents: List[Document],\n",
    "    max_chunk_size: int = 1000,\n",
    "    similarity_threshold: float = .7\n",
    ") -> List[Document]:\n",
    "    try:\n",
    "        from sklearn.cluster import DBSCAN\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install sklearn and sentence_transformers packages\")\n",
    "    \n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    all_chunks = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        text = doc.page_content\n",
    "        sentences = sent_tokenize(text)\n",
    "        # create embeddings for sentences\n",
    "        embeddings = model.encode(sentences)\n",
    "        # compute cosine similarity matrix\n",
    "        sim_matrix = cosine_similarity(embeddings)\n",
    "        # clustering sentences\n",
    "        clustering = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            distance_threshold=1 - similarity_threshold,\n",
    "            affinity=\"precomputed\",\n",
    "            linkage=\"average\"\n",
    "        )\n",
    "        \n",
    "        labels = clustering.fit_predict(1 - sim_matrix)\n",
    "        \n",
    "        # group sentences by cluster labels\n",
    "        clustered_sentences = defaultdict(list)\n",
    "        for label, sentence in zip(labels, sentences):\n",
    "            clustered_sentences[label].append(sentence)\n",
    "            \n",
    "        # create chunks\n",
    "        for cluster in clustered_sentences.values():\n",
    "            chunk_text = ' '.join(cluster)\n",
    "            if len(chunk_text) > max_chunk_size:\n",
    "                sub_chunks = re.findall(r\".{1,}\" + str(max_chunk_size) + r'}(?:\\s|$)', chunk_text)\n",
    "                for sub_chunk in sub_chunks:\n",
    "                    all_chunks.append(Document(\n",
    "                        page_content=sub_chunk.strip(),\n",
    "                        metadata=doc.metadata\n",
    "                    ))\n",
    "            else: \n",
    "                all_chunks.append(Document(\n",
    "                    page_content=chunk_text.strip(),\n",
    "                    metadata=doc.metadata\n",
    "                ))\n",
    "                \n",
    "    return all_chunks\n",
    "\n",
    "topic_chunks = topic_aware_text_splitting(documents, max_chunk_size=700, similarity_threshold=.7)\n",
    "print(topic_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06944a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG\n",
    "# -----------------------\n",
    "\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "MAX_TOKENS = 350\n",
    "OVERLAP_SENTENCES = 1\n",
    "\n",
    "CLAUSE_RE = re.compile(\n",
    "    r\"(Section|Clause|Article)\\s+\\d+(\\.\\d+)*(\\([a-z]\\))*\",\n",
    "    re.I\n",
    ")\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tok_len = lambda t: len(enc.encode(t))\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# HELPERS\n",
    "# -----------------------\n",
    "\n",
    "def extract_clauses(text):\n",
    "    return [\"\".join(m) for m in CLAUSE_RE.findall(text)]\n",
    "\n",
    "\n",
    "def find_offset(full, chunk, cursor):\n",
    "    pos = full.find(chunk, cursor)\n",
    "    return pos if pos != -1 else cursor\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# MAIN\n",
    "# -----------------------\n",
    "\n",
    "def topic_aware_text_splitting(\n",
    "    documents: List[Document],\n",
    "    similarity_threshold: float = 0.70,\n",
    ") -> List[Document]:\n",
    "\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "    all_chunks = []\n",
    "\n",
    "    for doc_idx, doc in enumerate(documents):\n",
    "\n",
    "        text = doc.page_content\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        if len(sentences) < 3:\n",
    "            all_chunks.append(doc)\n",
    "            continue\n",
    "\n",
    "        embeds = model.encode(sentences, normalize_embeddings=True)\n",
    "        sim = cosine_similarity(embeds)\n",
    "\n",
    "        clustering = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            distance_threshold=1 - similarity_threshold,\n",
    "            metric=\"precomputed\",\n",
    "            linkage=\"average\"\n",
    "        )\n",
    "\n",
    "        labels = clustering.fit_predict(1 - sim)\n",
    "\n",
    "        # ---- group while preserving order ----\n",
    "        groups = defaultdict(list)\n",
    "        for i, label in enumerate(labels):\n",
    "            groups[label].append((i, sentences[i]))\n",
    "\n",
    "        ordered_groups = sorted(groups.values(), key=lambda g: g[0][0])\n",
    "\n",
    "        cursor = 0\n",
    "        chunk_idx = 0\n",
    "\n",
    "        # ---- build token-bounded chunks ----\n",
    "        for group in ordered_groups:\n",
    "\n",
    "            ordered_sents = [s for _, s in group]\n",
    "\n",
    "            buf = []\n",
    "            buf_tokens = 0\n",
    "\n",
    "            for sent in ordered_sents:\n",
    "\n",
    "                t = tok_len(sent)\n",
    "\n",
    "                if buf_tokens + t > MAX_TOKENS and buf:\n",
    "\n",
    "                    chunk_text = \" \".join(buf)\n",
    "                    start = find_offset(text, chunk_text, cursor)\n",
    "                    end = start + len(chunk_text)\n",
    "\n",
    "                    meta = deepcopy(doc.metadata or {})\n",
    "                    meta.update({\n",
    "                        \"chunk_id\": f\"{doc_idx}_{chunk_idx}\",\n",
    "                        \"start_char\": start,\n",
    "                        \"end_char\": end,\n",
    "                        \"token_count\": tok_len(chunk_text),\n",
    "                        \"topic_cluster\": int(group[0][0]),\n",
    "                        \"clauses\": extract_clauses(chunk_text)\n",
    "                    })\n",
    "\n",
    "                    all_chunks.append(Document(\n",
    "                        page_content=chunk_text,\n",
    "                        metadata=meta\n",
    "                    ))\n",
    "\n",
    "                    cursor = end\n",
    "                    chunk_idx += 1\n",
    "\n",
    "                    # overlap\n",
    "                    buf = buf[-OVERLAP_SENTENCES:]\n",
    "                    buf_tokens = tok_len(\" \".join(buf))\n",
    "\n",
    "                buf.append(sent)\n",
    "                buf_tokens += t\n",
    "\n",
    "            if buf:\n",
    "                chunk_text = \" \".join(buf)\n",
    "                start = find_offset(text, chunk_text, cursor)\n",
    "                end = start + len(chunk_text)\n",
    "\n",
    "                meta = deepcopy(doc.metadata or {})\n",
    "                meta.update({\n",
    "                    \"chunk_id\": f\"{doc_idx}_{chunk_idx}\",\n",
    "                    \"start_char\": start,\n",
    "                    \"end_char\": end,\n",
    "                    \"token_count\": tok_len(chunk_text),\n",
    "                    \"clauses\": extract_clauses(chunk_text)\n",
    "                })\n",
    "\n",
    "                all_chunks.append(Document(\n",
    "                    page_content=chunk_text,\n",
    "                    metadata=meta\n",
    "                ))\n",
    "\n",
    "                cursor = end\n",
    "                chunk_idx += 1\n",
    "\n",
    "    return all_chunks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
